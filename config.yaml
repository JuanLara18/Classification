# ULTRA-OPTIMIZED AI Classification Configuration
# Hardware: 70GB RAM, 11 CPUs
# PERFORMANCE ENHANCEMENTS:
# 1. Unique value processing (massive speedup)
# 2. Optimized batch sizes for high-RAM systems
# 3. Enhanced parallel processing
# 4. Aggressive caching strategy

#######################
# File paths and basics
#######################
input_file: "input/HR_monthly_panel_translated.dta"
output_file: "output/HR_monthly_panel_classified.dta"
results_dir: "output/classification_results"

# Text columns to classify
text_columns:
  - position_name_english

#######################
# Text Preprocessing - MINIMAL for speed
#######################
preprocessing:
  lowercase: true
  remove_punctuation: false      # Keep for context
  remove_stopwords: false        # Keep all words
  lemmatize: false               # Skip for speed
  custom_stopwords: []
  min_word_length: 1
  max_length: 500                # Reduced for faster processing

#######################
# Classification Perspectives - ULTRA OPTIMIZED
#######################
clustering_perspectives:
  # HIGH-PERFORMANCE HR position classifier
  hr_position_classifier:
    type: "openai_classification"
    columns: 
      - position_name_english
    target_categories:
      - "Executive & Strategy"
      - "Legal, Compliance & Risk"
      - "Human Resources (HR)"
      - "Administration"
      - "Information Technology (IT)"
      - "Operations/Manufacturing"
      - "Supply Chain"
      - "Marketing & Communications"
      - "Sales"
      - "Research & Development (R&D)"
      - "Accounting & Finance"
      - "Customer Service & Support"
      - "Other"
    output_column: "position_category_gpt"
    
    # OpenAI Configuration - MAXIMUM PERFORMANCE
    llm_config:
      provider: "openai"
      model: "gpt-4o"         # Fastest and cheapest
      temperature: 0.1             # Maximum consistency
      max_tokens: 25               # REDUCED for speed
      timeout: 12                   # REDUCED timeout
      max_retries: 3               # Minimal retries
      backoff_factor: 1.5          # Fast backoff
      api_key_env: "OPENAI_API_KEY"
    
    # Classification settings - OPTIMIZED for UNIQUE VALUE PROCESSING
    classification_config:
      unknown_category: "Other"
      batch_size: 100              # INCREASED for unique processing
      include_unknown_in_categories: true
      
      # ULTRA-OPTIMIZED prompt for fastest processing
      prompt_template: |
        You are an expert HR classifier. Analyze the job position and classify it into ONE of the provided categories.

        POSITION TO CLASSIFY: "{text}"

        AVAILABLE CATEGORIES: {categories}

        DETAILED CATEGORY DESCRIPTIONS:
        1. Executive & Strategy - C-level executives, directors, strategic roles, general management, VP roles
        2. Legal, Compliance & Risk - Lawyers, legal counsel, compliance officers, risk managers, auditors, legal affairs  
        3. Human Resources (HR) - HR specialists, recruiters, training coordinators, HR managers, people operations, talent acquisition
        4. Administration - Administrative assistants, office managers, secretaries, clerical support, coordination roles
        5. Information Technology (IT) - Software developers, system administrators, IT support, network engineers, data analysts, programmers
        6. Operations/Manufacturing - Production workers, operators, supervisors, quality control, maintenance technicians, manufacturing
        7. Supply Chain - Logistics coordinators, procurement, warehouse staff, inventory managers, supply chain analysts
        8. Marketing & Communications - Marketing specialists, content creators, PR professionals, brand managers, communications
        9. Sales - Sales representatives, account managers, business development, customer acquisition roles
        10. Research & Development (R&D) - Research scientists, product developers, innovation roles, lab technicians, R&D engineers
        11. Accounting & Finance - Accountants, financial analysts, controllers, bookkeepers, treasury, budgeting roles
        12. Customer Service & Support - Customer service representatives, technical support, help desk, client relations
        13. Others - Any position that doesn't clearly fit the above categories

        CLASSIFICATION RULES:
        - Match the position to the MOST RELEVANT category based on primary job function
        - Consider job titles, responsibilities, and industry context
        - If unsure between categories, choose the one that represents the PRIMARY function
        - Use "Others" only if the position truly doesn't fit any specific category
        - Focus on the main job function, not secondary duties

        RESPOND WITH ONLY THE EXACT CATEGORY NAME from the list above.
    
    # Validation settings - SPEED OPTIMIZED
    validation:
      strict_category_matching: false
      fallback_strategy: "fuzzy_match"

#######################
# AI Classification Global Settings - MAXIMUM PERFORMANCE
#######################
ai_classification:
  # ENHANCED PARALLEL PROCESSING - Use ALL your CPUs
  parallel_processing:
    enabled: true
    max_workers: 11               # Use ALL 11 CPU cores
    chunk_size: 2000              # LARGE chunks for your RAM
    
  # ULTRA-AGGRESSIVE RATE LIMITING
  rate_limiting:
    requests_per_minute: 1000     # MAXIMUM throughput
    batch_delay_seconds: 0.01     # MINIMAL delay
    concurrent_requests: 20       # HIGH concurrency
    
  # MAXIMUM CACHING - Leverage your 70GB RAM
  caching:
    enabled: true
    cache_duration_days: 730      # 2-year cache
    cache_directory: "ai_cache"
    memory_cache_enabled: true
    memory_cache_size: 500000     # Cache 500K results in RAM
    preload_cache: true           # Load entire cache into RAM
    
    # ENHANCED cache settings
    compression_enabled: true     # Compress cache files
    cache_statistics: true        # Track cache performance
    auto_cleanup: true           # Clean expired entries
    
  # Cost management - HIGH LIMITS for large dataset
  cost_management:
    max_cost_per_run: 5000.0      # High limit for full dataset
    track_token_usage: true
    cost_alerts: true
    auto_optimize_batches: true
    
    # Cost optimization features
    unique_value_processing: true  # ENABLE unique processing
    estimate_before_run: true     # Estimate costs first
    
  # PERFORMANCE monitoring
  monitoring:
    log_api_calls: false          # Reduce logging overhead
    save_raw_responses: false     # Save storage/memory
    track_classification_accuracy: true
    progress_updates_every: 50    # Frequent progress updates
    
    # Performance metrics
    track_unique_ratio: true      # Track unique value efficiency
    track_cache_performance: true # Monitor cache hit rates
    memory_usage_monitoring: true # Monitor RAM usage
    
  # ULTRA-PERFORMANCE optimizations
  performance:
    use_async_processing: true    # Async API calls
    connection_pooling: true      # Reuse connections
    request_compression: true     # Compress requests
    response_streaming: true      # Stream responses
    
    # NEW performance features
    unique_value_optimization: true    # ENABLE unique processing
    memory_efficient_batching: true    # Optimize batches for RAM
    adaptive_batch_sizing: true        # Auto-adjust batch sizes
    pipeline_processing: true          # Pipeline API calls

#######################
# TESTING CONFIGURATION - Use for initial testing
#######################
# Uncomment the following section for testing with a small sample first:

# testing:
#   enabled: true
#   sample_size: 10000            # Test with 10K records first
#   sample_method: "random"       # or "first" for first N records
#   output_file: "output/HR_sample_test.dta"

#######################
# Enhanced Spark Configuration - OPTIMIZED for 70GB RAM
#######################
spark:
  executor_memory: "20g"          # Conservative memory allocation
  driver_memory: "10g"            # Large driver memory  
  executor_cores: 3               # Balanced cores per executor
  default_parallelism: 11         # Match CPU count
  max_executors: 3                # 3 executors Ã— 20GB = 60GB used
  
  # Advanced Spark settings
  executor_memory_fraction: 0.8   # Use 80% of executor memory
  driver_max_result_size: "4g"    # Large result size
  sql_adaptive_enabled: true      # Enable adaptive query execution
  sql_adaptive_coalesce_partitions: true

#######################
# Enhanced Checkpointing - OPTIMIZED for large datasets
#######################
checkpoint:
  enabled: true
  interval: 500                   # Checkpoint every 500 unique values
  directory: "checkpoints"
  max_checkpoints: 3              # Keep fewer checkpoints
  compression: true               # Compress for space
  async_saving: true              # Async checkpoint saving
  
  # Advanced checkpoint features
  incremental_checkpoints: true   # Only save changes
  memory_checkpoints: true        # Keep checkpoints in RAM
  checkpoint_validation: true     # Validate checkpoints

#######################
# Optimized Logging - REDUCED overhead
#######################
logging:
  level: "INFO"
  log_file: "logs/hr_classification_optimized.log"
  console_output: true
  
  # Reduced logging for performance
  log_rotation: true
  max_log_size: "50MB"           # Smaller log files
  log_compression: true
  async_logging: true            # Async logging
  
  # Performance logging
  performance_logging: true      # Log performance metrics
  memory_logging: true          # Log memory usage

#######################
# MAXIMUM Performance Options
#######################
options:
  seed: 42
  save_intermediate: false       # Don't save intermediate files
  clean_intermediate_on_success: true
  
  # PERFORMANCE optimization flags
  memory_monitoring: true
  gc_frequency: 500             # Garbage collection every 500 ops
  performance_profiling: true
  detailed_timing: true
  
  # NEW optimization options
  unique_processing_enabled: true    # ENABLE unique value processing
  batch_optimization: true          # Optimize batch processing
  memory_preallocation: true        # Pre-allocate memory
  cpu_affinity: true               # Set CPU affinity for threads
  
  # Resource management
  max_memory_usage: "60g"          # Maximum memory usage
  memory_warning_threshold: 0.85   # Warn at 85% memory usage
  auto_resource_scaling: true      # Auto-scale resources

#######################
# Feature Extraction - MINIMAL (required for compatibility)
#######################
feature_extraction:
  method: 'embedding'
  embedding:
    model: 'sentence-transformers'
    sentence_transformers:
      model_name: 'all-MiniLM-L6-v2'

#######################
# Cluster Labeling - FAST method
#######################
cluster_labeling:
  method: "tfidf"

#######################
# Evaluation - STREAMLINED
#######################
evaluation:
  metrics:
    - "distribution_analysis"
    - "cost_analysis"
    - "performance_metrics"
    - "unique_value_analysis"      # NEW metric
  visualizations:
    - "distribution_plot"
    - "performance_plot"           # NEW visualization
  output_format:
    - "html"
    - "json"