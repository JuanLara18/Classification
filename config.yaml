# ULTRA-OPTIMIZED AI Classification Configuration
# Hardware: 70GB RAM, 11 CPUs
# PERFORMANCE ENHANCEMENTS:
# 1. Unique value processing (massive speedup)
# 2. Optimized batch sizes for high-RAM systems
# 3. Enhanced parallel processing
# 4. Aggressive caching strategy

#######################
# File paths and basics
#######################
input_file: "input/HR_monthly_panel_translated.dta"
output_file: "output/HR_monthly_panel_classified.dta"
results_dir: "output/classification_results"

# Text columns to classify
text_columns:
  - position_name_english

#######################
# Text Preprocessing - MINIMAL for speed
#######################
preprocessing:
  lowercase: true
  remove_punctuation: false      # Keep for context
  remove_stopwords: false        # Keep all words
  lemmatize: false               # Skip for speed
  custom_stopwords: []
  min_word_length: 1
  max_length: 500                # Reduced for faster processing

#######################
# Classification Perspectives - ULTRA OPTIMIZED
#######################
clustering_perspectives:
  # HIGH-PERFORMANCE HR position classifier
  hr_position_classifier:
    type: "openai_classification"
    columns: 
      - position_name_english
    target_categories:
      - "Executive & Senior Management"
      - "Legal, Compliance & Risk"
      - "Human Resources (HR)"
      - "Administrative Support"
      - "Information Technology (IT)"
      - "Operations & Manufacturing"
      - "Supply Chain & Logistics"
      - "Marketing & Communications"
      - "Sales & Business Development"
      - "Research & Development (R&D)"
      - "Finance & Accounting"
      - "Customer Service & Support"
      - "Engineering"
      - "Healthcare & Medical"
      - "Education & Training"
      - "Consulting & Advisory"
      - "Other/Unknown"
    output_column: "position_category_gpt"
    
    # OpenAI Configuration - MAXIMUM PERFORMANCE
    llm_config:
      provider: "openai"
      model: "gpt-4o-mini"         # Fastest and cheapest
      temperature: 0.0             # Maximum consistency
      max_tokens: 15               # REDUCED for speed
      timeout: 8                   # REDUCED timeout
      max_retries: 2               # Minimal retries
      backoff_factor: 1.2          # Fast backoff
      api_key_env: "OPENAI_API_KEY"
    
    # Classification settings - OPTIMIZED for UNIQUE VALUE PROCESSING
    classification_config:
      unknown_category: "Other/Unknown"
      batch_size: 100              # INCREASED for unique processing
      include_unknown_in_categories: true
      
      # ULTRA-OPTIMIZED prompt for fastest processing
      prompt_template: |
        Classify job: "{text}"
        
        Categories: Executive, Legal, HR, Admin, IT, Operations, Supply Chain, Marketing, Sales, R&D, Finance, Customer Service, Engineering, Healthcare, Education, Consulting, Other
        
        Answer:
    
    # Validation settings - SPEED OPTIMIZED
    validation:
      strict_category_matching: false  # Flexible for speed
      fallback_strategy: "unknown"

#######################
# AI Classification Global Settings - MAXIMUM PERFORMANCE
#######################
ai_classification:
  # ENHANCED PARALLEL PROCESSING - Use ALL your CPUs
  parallel_processing:
    enabled: true
    max_workers: 11               # Use ALL 11 CPU cores
    chunk_size: 2000              # LARGE chunks for your RAM
    
  # ULTRA-AGGRESSIVE RATE LIMITING
  rate_limiting:
    requests_per_minute: 1000     # MAXIMUM throughput
    batch_delay_seconds: 0.01     # MINIMAL delay
    concurrent_requests: 20       # HIGH concurrency
    
  # MAXIMUM CACHING - Leverage your 70GB RAM
  caching:
    enabled: true
    cache_duration_days: 730      # 2-year cache
    cache_directory: "ai_cache"
    memory_cache_enabled: true
    memory_cache_size: 500000     # Cache 500K results in RAM
    preload_cache: true           # Load entire cache into RAM
    
    # ENHANCED cache settings
    compression_enabled: true     # Compress cache files
    cache_statistics: true        # Track cache performance
    auto_cleanup: true           # Clean expired entries
    
  # Cost management - HIGH LIMITS for large dataset
  cost_management:
    max_cost_per_run: 5000.0      # High limit for full dataset
    track_token_usage: true
    cost_alerts: true
    auto_optimize_batches: true
    
    # Cost optimization features
    unique_value_processing: true  # ENABLE unique processing
    estimate_before_run: true     # Estimate costs first
    
  # PERFORMANCE monitoring
  monitoring:
    log_api_calls: false          # Reduce logging overhead
    save_raw_responses: false     # Save storage/memory
    track_classification_accuracy: true
    progress_updates_every: 50    # Frequent progress updates
    
    # Performance metrics
    track_unique_ratio: true      # Track unique value efficiency
    track_cache_performance: true # Monitor cache hit rates
    memory_usage_monitoring: true # Monitor RAM usage
    
  # ULTRA-PERFORMANCE optimizations
  performance:
    use_async_processing: true    # Async API calls
    connection_pooling: true      # Reuse connections
    request_compression: true     # Compress requests
    response_streaming: true      # Stream responses
    
    # NEW performance features
    unique_value_optimization: true    # ENABLE unique processing
    memory_efficient_batching: true    # Optimize batches for RAM
    adaptive_batch_sizing: true        # Auto-adjust batch sizes
    pipeline_processing: true          # Pipeline API calls

#######################
# TESTING CONFIGURATION - Use for initial testing
#######################
# Uncomment the following section for testing with a small sample first:

# testing:
#   enabled: true
#   sample_size: 10000            # Test with 10K records first
#   sample_method: "random"       # or "first" for first N records
#   output_file: "output/HR_sample_test.dta"

#######################
# Enhanced Spark Configuration - OPTIMIZED for 70GB RAM
#######################
spark:
  executor_memory: "20g"          # Conservative memory allocation
  driver_memory: "10g"            # Large driver memory  
  executor_cores: 3               # Balanced cores per executor
  default_parallelism: 11         # Match CPU count
  max_executors: 3                # 3 executors Ã— 20GB = 60GB used
  
  # Advanced Spark settings
  executor_memory_fraction: 0.8   # Use 80% of executor memory
  driver_max_result_size: "4g"    # Large result size
  sql_adaptive_enabled: true      # Enable adaptive query execution
  sql_adaptive_coalesce_partitions: true

#######################
# Enhanced Checkpointing - OPTIMIZED for large datasets
#######################
checkpoint:
  enabled: true
  interval: 500                   # Checkpoint every 500 unique values
  directory: "checkpoints"
  max_checkpoints: 3              # Keep fewer checkpoints
  compression: true               # Compress for space
  async_saving: true              # Async checkpoint saving
  
  # Advanced checkpoint features
  incremental_checkpoints: true   # Only save changes
  memory_checkpoints: true        # Keep checkpoints in RAM
  checkpoint_validation: true     # Validate checkpoints

#######################
# Optimized Logging - REDUCED overhead
#######################
logging:
  level: "INFO"
  log_file: "logs/hr_classification_optimized.log"
  console_output: true
  
  # Reduced logging for performance
  log_rotation: true
  max_log_size: "50MB"           # Smaller log files
  log_compression: true
  async_logging: true            # Async logging
  
  # Performance logging
  performance_logging: true      # Log performance metrics
  memory_logging: true          # Log memory usage

#######################
# MAXIMUM Performance Options
#######################
options:
  seed: 42
  save_intermediate: false       # Don't save intermediate files
  clean_intermediate_on_success: true
  
  # PERFORMANCE optimization flags
  memory_monitoring: true
  gc_frequency: 500             # Garbage collection every 500 ops
  performance_profiling: true
  detailed_timing: true
  
  # NEW optimization options
  unique_processing_enabled: true    # ENABLE unique value processing
  batch_optimization: true          # Optimize batch processing
  memory_preallocation: true        # Pre-allocate memory
  cpu_affinity: true               # Set CPU affinity for threads
  
  # Resource management
  max_memory_usage: "60g"          # Maximum memory usage
  memory_warning_threshold: 0.85   # Warn at 85% memory usage
  auto_resource_scaling: true      # Auto-scale resources

#######################
# Feature Extraction - MINIMAL (required for compatibility)
#######################
feature_extraction:
  method: 'embedding'
  embedding:
    model: 'sentence-transformers'
    sentence_transformers:
      model_name: 'all-MiniLM-L6-v2'

#######################
# Cluster Labeling - FAST method
#######################
cluster_labeling:
  method: "tfidf"

#######################
# Evaluation - STREAMLINED
#######################
evaluation:
  metrics:
    - "distribution_analysis"
    - "cost_analysis"
    - "performance_metrics"
    - "unique_value_analysis"      # NEW metric
  visualizations:
    - "distribution_plot"
    - "performance_plot"           # NEW visualization
  output_format:
    - "html"
    - "json"