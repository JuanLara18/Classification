# FULLY FIXED Maintenance Classification + Clustering
# Fixed unique value processing, file saving, AND visualization issues

input_file: "input/Maintenance_Classified_ErrorType.dta"
output_file: "output/Maintenance_Hybrid_Fixed.dta"
results_dir: "output/maintenance_fixed"  # Different directory to avoid conflicts

# ALL maintenance text columns
text_columns:
  - CauseDescription_EN
  - CauseLongText_EN  
  - TechnicalObjectDescription_EN
  - DamagePatternLongText_EN

# TESTING CONFIGURATION - Enabled for 5-minute test
testing:
  enabled: true
  sample_size: 1000
  sample_method: "random"
  output_file: "output/Maintenance_test_fully_fixed.dta"

# FIXED: Less aggressive preprocessing
preprocessing:
  lowercase: false
  remove_punctuation: false
  remove_stopwords: false
  lemmatize: false
  min_word_length: 1
  max_length: 1000

# 5 PERSPECTIVES: 1 AI + 4 Clustering
clustering_perspectives:
  # AI Classification - 5 main categories
  ai_root_causes:
    type: "openai_classification"
    columns: ["CauseDescription_EN"]
    target_categories:
      - "Mechanical Failure"
      - "Electrical Issues" 
      - "Human Error"
      - "Material/Design Defect"
      - "Other"
    output_column: "ai_cause_5groups"
    
    llm_config:
      provider: "openai"
      model: "gpt-4o-mini"
      temperature: 0.0
      max_tokens: 15
      api_key_env: "OPENAI_API_KEY"
    
    classification_config:
      batch_size: 50
      unknown_category: "Other"

  # Clustering perspectives
  broad_categories:
    type: "clustering"
    algorithm: "kmeans"
    columns: ["CauseDescription_EN", "CauseLongText_EN"]
    output_column: "cluster_2groups"
    params:
      n_clusters: 2
      n_init: 5
      max_iter: 100
      random_state: 42

  detailed_causes:
    type: "clustering"
    algorithm: "kmeans"
    columns: ["CauseDescription_EN"]
    output_column: "cluster_7groups"
    params:
      n_clusters: 7
      n_init: 5
      max_iter: 100
      random_state: 42

  equipment_patterns:
    type: "clustering"
    algorithm: "kmeans"
    columns: ["TechnicalObjectDescription_EN", "DamagePatternLongText_EN"]
    output_column: "cluster_10groups"
    params:
      n_clusters: 10
      n_init: 5
      max_iter: 100
      random_state: 42

  fine_damage_patterns:
    type: "clustering"
    algorithm: "kmeans"
    columns: ["DamagePatternLongText_EN"]
    output_column: "cluster_20groups"
    params:
      n_clusters: 20
      n_init: 5
      max_iter: 100
      random_state: 42

# Feature extraction settings
feature_extraction:
  method: "tfidf"
  tfidf:
    max_features: 1000
    min_df: 1
    max_df: 0.95
    ngram_range: [1, 2]

# AI Classification settings
ai_classification:
  cost_management:
    max_cost_per_run: 10.0
  
  caching:
    enabled: true
    cache_directory: "ai_cache"
    preload_cache: true
  
  rate_limiting:
    requests_per_minute: 500
    concurrent_requests: 5
  
  parallel_processing:
    max_workers: 4

# Cluster labeling
cluster_labeling:
  method: "openai"  # Changed from "tfidf" to "openai"
  openai:
    model: "gpt-4o-mini"
    temperature: 0.1
    max_tokens: 50
    api_key_env: "OPENAI_API_KEY"
  tfidf:
    top_terms: 5

# Basic analysis
cluster_analysis:
  enabled: true
  top_terms_count: 8
  examples_count: 3
  create_detailed_reports: false
  cross_perspective_analysis: false

# FIXED: Enable visualizations with safer settings
evaluation:
  metrics:
    - 'silhouette_score'
    - 'davies_bouldin_score'
  visualizations:
    - 'distribution_plot'    # Re-enabled with fixes
    - 'embeddings_plot'      # Re-enabled with fixes
  output_format:
    - 'html'
    - 'json'

# Spark settings for your system
spark:
  executor_memory: "22g"
  driver_memory: "18g"
  executor_cores: 4
  default_parallelism: 12

# Disable checkpointing to save disk space
checkpoint:
  enabled: false

# Logging
logging:
  level: "INFO"
  console_output: true
  log_file: "logs/fully_fixed_classification.log"

# Options
options:
  seed: 42
  save_intermediate: false
  clean_intermediate_on_success: true